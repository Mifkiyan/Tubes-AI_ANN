{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer Class\n",
    "class Layer:\n",
    "    def __init__(self, num_neuron: int, activation: str, weights: np.array, bias: np.array):\n",
    "        self.num_neuron = num_neuron\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        self.activation = activation\n",
    "        if activation == 'linear':\n",
    "            self.function = lambda x: x\n",
    "            self.derivative = lambda x: 1\n",
    "        elif activation == 'relu':\n",
    "            self.function = lambda x: np.maximum(0, x)\n",
    "            self.derivative = lambda x: np.where(x > 0, 1, 0)\n",
    "        elif activation == 'sigmoid':\n",
    "            self.function = lambda x: 1 / (1 + np.exp(-x))\n",
    "            self.derivative = lambda x: self.function(x) * (1 - self.function(x))\n",
    "        elif activation == 'softmax':\n",
    "            self.function = lambda x: np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
    "            self.derivative = lambda x: self.function(x) - self.function(x) ** 2\n",
    "        else:\n",
    "            raise ValueError('Invalid activation function')\n",
    "\n",
    "    def forward(self, input: np.array):\n",
    "        self.input = input\n",
    "        self.net = np.dot(input, self.weights) + self.bias\n",
    "        self.output = self.function(self.net)\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN:\n",
    "    def __init__(self, input_size: int, layers: list, learning_rate: float, epochs: int, batch_size: int, threshold: float, initial_weights: list):\n",
    "        self.input_size = input_size\n",
    "        self.layers = layers\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.threshold = threshold\n",
    "        self.loss = []\n",
    "        self.initial_weights = initial_weights\n",
    "        self.final_weights = []\n",
    "        self.stopped_by = \"\"\n",
    "\n",
    "    def add_layer(self, layer: Layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def forward(self, input: np.array):\n",
    "        output = input\n",
    "        for layer in self.layers:\n",
    "            output = layer.forward(output)\n",
    "        return output\n",
    "    \n",
    "    def backward(self, target: np.array):\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            layer = self.layers[i]\n",
    "            if i == len(self.layers) - 1:\n",
    "                if layer.activation == 'softmax':\n",
    "                    layer.delta = layer.output - target\n",
    "                else:\n",
    "                    error = layer.output - target\n",
    "                    layer.delta = error * layer.derivative(layer.net)\n",
    "            else:\n",
    "                layer.delta = np.dot(self.layers[i+1].delta, self.layers[i+1].weights.T) * layer.derivative(layer.net)\n",
    "            layer.weights -= self.learning_rate * np.dot(layer.input.T, layer.delta)\n",
    "            layer.bias -= self.learning_rate * np.squeeze(np.sum(layer.delta, axis=0))\n",
    "\n",
    "    def train(self, X_train: np.array, y_train: np.array):\n",
    "        for i in range(len(self.layers)):\n",
    "            self.layers[i].weights = np.array(self.initial_weights[i][1:])\n",
    "            self.layers[i].bias = np.array(self.initial_weights[i][0])\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            error_epoch = 0\n",
    "            # Mini-batch\n",
    "            for i in range(0, X_train.shape[0], self.batch_size):\n",
    "                X_batch = X_train[i:i + self.batch_size]\n",
    "                y_batch = y_train[i:i + self.batch_size]\n",
    "                output = self.forward(X_batch)\n",
    "                self.backward(y_batch)\n",
    "                if self.layers[-1].activation == 'softmax':\n",
    "                    error_batch = np.mean(-y_batch * np.log(output))\n",
    "                else:\n",
    "                    error_batch = np.mean((output - y_batch)**2)\n",
    "                error_epoch += error_batch\n",
    "            error_epoch /= (X_train.shape[0] / self.batch_size)\n",
    "            self.loss.append(error_epoch)\n",
    "            print(f\"Epoch {epoch+1}/{self.epochs}, Error: {error_epoch:.6f}\")\n",
    "            if error_epoch <= self.threshold:\n",
    "                print(f\"Training stopped at epoch {epoch+1} with error {error_epoch:.6f}\")\n",
    "                self.stopped_by = \"error_threshold\"\n",
    "                break\n",
    "        if epoch == self.epochs - 1:\n",
    "            self.stopped_by = \"max_iteration\"\n",
    "        self.final_weights = [[layer.bias.tolist()] + layer.weights.tolist() for layer in self.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = str(input(\"Enter the input file name (JSON only): \"))\n",
    "print(f\"Test case: {input_file}.json\\n\")\n",
    "with open(f\"test-case/{input_file}.json\", \"r\") as file:\n",
    "    model = json.load(file)\n",
    "\n",
    "input_size = model[\"case\"][\"model\"][\"input_size\"]\n",
    "layers = []\n",
    "for layer in model[\"case\"][\"model\"][\"layers\"]:\n",
    "    layers.append(Layer(layer[\"number_of_neurons\"], layer[\"activation_function\"], None, None))\n",
    "learning_rate = model[\"case\"][\"learning_parameters\"][\"learning_rate\"]\n",
    "epochs = model[\"case\"][\"learning_parameters\"][\"max_iteration\"]\n",
    "batch_size = model[\"case\"][\"learning_parameters\"][\"batch_size\"]\n",
    "threshold = model[\"case\"][\"learning_parameters\"][\"error_threshold\"]\n",
    "initial_weights = model[\"case\"][\"initial_weights\"]\n",
    "ffnn = FFNN(input_size, layers, learning_rate, epochs, batch_size, threshold, initial_weights)\n",
    "\n",
    "X_train = np.array(model[\"case\"][\"input\"])\n",
    "y_train = np.array(model[\"case\"][\"target\"])\n",
    "ffnn.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_stopped_by = model[\"expect\"][\"stopped_by\"]\n",
    "if ffnn.stopped_by != expected_stopped_by:\n",
    "    print(f\"Test case failed: Stopped by {ffnn.stopped_by}, expected {expected_stopped_by}\")\n",
    "else:\n",
    "    print(f\"Stopped by {ffnn.stopped_by}\")\n",
    "\n",
    "print(\"Final Weights:\")\n",
    "for i, weights in enumerate(ffnn.final_weights):\n",
    "    for j, row in enumerate(weights):\n",
    "        print(\"[\" + \" \".join([f\"{val:.6f}\" for val in row]) + \"]\")\n",
    "    print()\n",
    "\n",
    "if \"final_weights\" in model[\"expect\"]:\n",
    "    expected_weights = model[\"expect\"][\"final_weights\"]\n",
    "    for i in range(len(expected_weights)):\n",
    "        diff = np.array(ffnn.final_weights[i]) - np.array(expected_weights[i])\n",
    "        sse = np.sum(diff**2)\n",
    "        if sse > 1e-7:\n",
    "            print(f\"Test case failed: Final weight does not match. SSE = {sse:.8f}\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"All test case passed!\")\n",
    "else:\n",
    "    print(\"No expected final weights provided in the test case.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
